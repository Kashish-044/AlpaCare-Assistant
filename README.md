# ğŸ¥ AlpaCare MedInstruct Assistant

## ğŸ“˜ Project Overview
**AlpaCare MedInstruct Assistant** is a fine-tuned **medical instruction language model** that provides safe, educational responses to health-related prompts.  
It uses **LoRA/PEFT fine-tuning** on the [`lavita/AlpaCare-MedInstruct-52k`](https://huggingface.co/datasets/lavita/AlpaCare-MedInstruct-52k) dataset to teach a small (<7B) LLM to follow medical-style instructions safely.

> âš ï¸ **Disclaimer:** This project is for **educational purposes only** and does **not provide medical advice, diagnosis, or prescriptions**. Always consult a qualified clinician.

---

## ğŸ§  Model Architecture & Approach
- **Base Model:** `stabilityai/stablelm-tuned-alpha-3b` 
- **Fine-tuning Method:** LoRA (Low-Rank Adaptation) via Hugging Face PEFT
- **Frameworks:** Transformers, PEFT, bitsandbytes, Accelerate
- **Training Environment:** Google Colab (T4/A100 GPU)
- **Safety Measures:**
  - Each model output includes a disclaimer
  - No dosage, prescription, or diagnosis responses
  - Human evaluation by 30+ medically literate reviewers

---
## ğŸ§© Repository Structure
AlpaCare-MedInstruct-Assistant/
- â”‚
- â”œâ”€â”€ data_loader.py
- â”œâ”€â”€ notebooks/
- â”‚ â”œâ”€â”€ colab_finetune.ipynb 
- â”‚ â”œâ”€â”€ inference_demo.ipynb 
- â”‚
- â”œâ”€â”€ REPORT.md
- â”œâ”€â”€ requirements.txt
- â””â”€â”€ README.md
---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/Kashish-044/AlpaCare-Assistant.git
cd AlpaCare-MedInstruct-Assistant
```
## ğŸ“‚ Dataset Information
- Dataset: lavita/AlpaCare-MedInstruct-52k
- Split: 90% training / 5% validation / 5% testing
- Cleaning: Removed duplicates, filtered incomplete or unsafe entries
- Preprocessing: Used tokenizer from base model for encoding text

## ğŸš€ How to Run
ğŸ”¹ Fine-tuning
Open notebooks/colab_finetune.ipynb in Google Colab and run all cells sequentially.
It will:
- Install all dependencies
- Load and preprocess dataset
- Fine-tune model using LoRA
- Save adapter weights via:
```bash
peft_model.save_pretrained("adapters/alpacare-lora")
```
##ğŸ”¹ Inference
Run `notebooks/inference_demo.ipynb` to test model responses:
```
Prompt: "What should I do for a mild headache?"
Response: "Try hydration, rest, and monitor symptoms. This is educational only â€” consult a qualified clinician."
```

## ğŸ“Š Evaluation
- Human Review: 30+ medically literate evaluators
- Metrics: BLEU, ROUGE, and safety compliance
- Findings: Majority of outputs rated safe, factual, and well-structured

## âš–ï¸ Limitations
- The model cannot diagnose or prescribe
- Trained only on educational data; may not generalize to clinical decisions
- Limited by dataset coverage and model size (<7B)

## ğŸ“š References
- Hugging Face PEFT
- LoRA: Low-Rank Adaptation Paper
- lavita/AlpaCare-MedInstruct-52k Dataset

